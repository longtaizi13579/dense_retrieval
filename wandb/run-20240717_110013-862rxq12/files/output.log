/home/yeqin/anaconda3/envs/retriever/lib/python3.8/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()

































































Inference Embeddings: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 3253/3253 [02:35<00:00, 20.89it/s]












Inference Embeddings: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 85/85 [00:24<00:00,  3.48it/s]






























































































































































































































































































































































































































































































































































































100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 832751/832751 [19:20<00:00, 717.32it/s]
Map:   0%|                                                                                                            | 0/832751 [00:00<?, ? examples/s]
Traceback (most recent call last):
  File "/home/yeqin/anaconda3/envs/retriever/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 270, in __getattr__
    return self.data[item]
KeyError: 'cuda'
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "retriever_training.py", line 189, in <module>
    data_loader = build_train_data(data_args.file_path, model_args.model_name_or_path, tokenizer, identifiers_index, name_to_identifiers_id, all_candidates, data_args)
  File "retriever_training.py", line 137, in build_train_data
    encode_ds = dataset.map(tokenize, batched=True, batch_size=training_args.train_batch_size)
  File "/home/yeqin/anaconda3/envs/retriever/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 602, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/yeqin/anaconda3/envs/retriever/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 567, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/yeqin/anaconda3/envs/retriever/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 3161, in map
    for rank, done, content in Dataset._map_single(**dataset_kwargs):
  File "/home/yeqin/anaconda3/envs/retriever/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 3552, in _map_single
    batch = apply_function_on_filtered_inputs(
  File "/home/yeqin/anaconda3/envs/retriever/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 3421, in apply_function_on_filtered_inputs
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
  File "retriever_training.py", line 110, in tokenize
    inputs_querys_ids = tokenizer(
  File "/home/yeqin/anaconda3/envs/retriever/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 272, in __getattr__
    raise AttributeError
AttributeError